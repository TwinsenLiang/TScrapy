# TScrapy 开发路线图

## ✅ 已完成

### v1.0.0 - 基础爬虫功能
- [x] 使用 Selenium 支持 JavaScript 渲染
- [x] 命令行参数配置
- [x] 多格式输出（HTML、TXT、JSON）
- [x] 深度控制爬取
- [x] 域名限制
- [x] 请求延迟和防封
- [x] 可视/无头模式切换
- [x] 错误处理和统计

### v1.1.0 - 深度逻辑优化
- [x] 修改深度逻辑：depth 1 = 起始页面本身，depth 2 = 起始页面的链接

## 🚧 进行中

### v1.2.0 - DOM 节点选择器
**优先级**: 高
**目标**: 允许用户指定只爬取某个 DOM 节点下的链接

**功能需求**:
- [ ] 添加 `--selector` 参数，支持 CSS 选择器
- [ ] 添加 `--xpath` 参数，支持 XPath 选择器
- [ ] 在指定的 DOM 节点内提取链接
- [ ] 示例：
  ```bash
  # 只爬取 id="main-content" 下的链接
  python scraper.py URL --selector "#main-content"

  # 只爬取 class="article-links" 下的链接
  python scraper.py URL --selector ".article-links"

  # 使用 XPath
  python scraper.py URL --xpath "//div[@id='content']"
  ```

**实现要点**:
- 修改 `extract_links()` 方法，支持在指定容器内查找链接
- 同时支持 CSS Selector 和 XPath
- 如果未指定选择器，默认在整个页面提取链接
- 添加错误处理：选择器无匹配时给出警告

## 📋 计划中

### v1.3.0 - 链接过滤增强
**优先级**: 中

- [ ] 添加 `--include` 参数，只爬取匹配的 URL 模式
- [ ] 支持正则表达式匹配
- [ ] URL 黑白名单配置文件

### v1.4.0 - 性能优化
**优先级**: 中

- [ ] 支持多进程并发爬取
- [ ] 添加爬取队列持久化（断点续爬）
- [ ] 添加浏览器缓存复用

### v1.5.0 - 数据处理增强
**优先级**: 低

- [ ] 支持自定义数据提取规则
- [ ] 导出为 CSV、Excel 格式
- [ ] 添加数据去重功能
- [ ] 支持提取特定字段（标题、作者、日期等）

### v1.6.0 - 高级功能
**优先级**: 低

- [ ] 支持登录后爬取
- [ ] 支持处理分页
- [ ] 支持 JavaScript 交互（点击、滚动等）
- [ ] 添加 API 接口模式
- [ ] 支持 robots.txt 自动解析

### v2.0.0 - 架构重构
**优先级**: 未定

- [ ] 插件系统
- [ ] Web UI 界面
- [ ] 分布式爬取支持
- [ ] 云端调度

## 💡 功能建议

欢迎提交 Issue 提出新的功能建议！

## 📝 版本历史

- **v1.1.0** (2024-12-11): 优化深度逻辑
- **v1.0.0** (2024-12-11): 初始版本，基础爬虫功能

---

*最后更新: 2024-12-11*
